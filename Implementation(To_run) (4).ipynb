{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "player_career = pd.read_csv(\"https://raw.githubusercontent.com/Cameron2003M/DS-340W-Project/main/Player%20Career%20Info.csv\")\n",
        "player_total = pd.read_csv(\"https://raw.githubusercontent.com/Cameron2003M/DS-340W-Project/main/Player%20Totals.csv\")\n",
        "\n",
        "\n",
        "\n",
        "player_career.columns = player_career.columns.str.strip()\n",
        "player_total.columns = player_total.columns.str.strip()\n",
        "\n",
        "df = player_total.merge(\n",
        "    player_career[['player_id','player','num_seasons','first_seas','last_seas']],\n",
        "    on=\"player_id\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "if 'player_x' in df.columns:\n",
        "    df = df.drop(columns=['player_x'])\n",
        "if 'player_y' in df.columns:\n",
        "    df = df.rename(columns={'player_y':'player'})\n",
        "\n",
        "df = df[df['lg'] == 'NBA']\n",
        "df = df[df['experience'] == 2]\n",
        "df = df[df['last_seas'] != 2024]\n",
        "\n",
        "count_stats = ['g','gs','mp','fg','fga','x3p','x3pa','x2p','x2pa','ft','fta','orb','drb','trb','ast','stl','blk','tov','pf','pts']\n",
        "\n",
        "def first_nonnull(s):\n",
        "    s2 = s.dropna()\n",
        "    return s2.iloc[0] if len(s2) else np.nan\n",
        "\n",
        "agg_dict = {c: 'sum' for c in count_stats}\n",
        "agg_dict.update({\n",
        "    'player': first_nonnull,\n",
        "    'age': first_nonnull,\n",
        "    'pos': first_nonnull,\n",
        "    'first_seas': first_nonnull,\n",
        "    'num_seasons': first_nonnull\n",
        "})\n",
        "\n",
        "grouped = df.groupby(['player_id','season'], as_index=False).agg(agg_dict)\n",
        "tm_counts = df.groupby(['player_id','season'])['tm'].nunique().reset_index().rename(columns={'tm':'num_tm'})\n",
        "df2 = grouped.merge(tm_counts, on=['player_id','season'], how='left')\n",
        "\n",
        "df2['surv10'] = (df2['num_seasons'].astype(float) >= 10).astype(int)\n",
        "\n",
        "df2['fg_percent'] = df2['fg'] / df2['fga'].replace(0, np.nan)\n",
        "df2['x3p_percent'] = df2['x3p'] / df2['x3pa'].replace(0, np.nan)\n",
        "df2['ft_percent'] = df2['ft'] / df2['fta'].replace(0, np.nan)\n",
        "\n",
        "df2['mpg'] = df2['mp'] / df2['g'].replace(0, np.nan)\n",
        "df2['ppg'] = df2['pts'] / df2['g'].replace(0, np.nan)\n",
        "df2['rpg'] = df2['trb'] / df2['g'].replace(0, np.nan)\n",
        "df2['apg'] = df2['ast'] / df2['g'].replace(0, np.nan)\n",
        "df2['spg'] = df2['stl'] / df2['g'].replace(0, np.nan)\n",
        "df2['bpg'] = df2['blk'] / df2['g'].replace(0, np.nan)\n",
        "df2['tpg'] = df2['tov'] / df2['g'].replace(0, np.nan)\n",
        "df2['pfpg'] = df2['pf'] / df2['g'].replace(0, np.nan)\n",
        "\n",
        "df2['ast_to'] = df2['ast'] / df2['tov'].replace(0, np.nan)\n",
        "df2['ast_plus_pts_to'] = (df2['ast'] + df2['pts']) / df2['tov'].replace(0, np.nan)\n",
        "\n",
        "ratio_cols = ['fg_percent','x3p_percent','ft_percent','mpg','ppg','rpg','apg','spg','bpg','tpg','pfpg','ast_to','ast_plus_pts_to']\n",
        "df2[ratio_cols] = df2[ratio_cols].fillna(0)\n",
        "\n",
        "df2['pos_primary'] = df2['pos'].astype(str).str.split('-').str[0]\n",
        "pos_dummies = pd.get_dummies(df2['pos_primary'], prefix='pos')\n",
        "df2 = pd.concat([df2, pos_dummies], axis=1)\n",
        "\n",
        "feature_cols = ['age','g','mp','ppg','rpg','apg','spg','bpg','tpg','pfpg','fg_percent','x3p_percent','ft_percent','ast_to','ast_plus_pts_to','num_tm'] + list(pos_dummies.columns)\n",
        "\n",
        "X = df2[feature_cols]\n",
        "y = df2['surv10']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=23, stratify=y)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(penalty='l2', solver='liblinear', max_iter=3000))\n",
        "])\n",
        "\n",
        "param_grid = {'clf__C': np.logspace(-3, 3, 25)}\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=20, random_state=23)\n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "test_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"Best C:\", grid.best_params_)\n",
        "print(\"Holdout AUC:\", round(test_auc, 3))\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(random_state=23, eval_metric='logloss')\n",
        "xgb_pipe = Pipeline([('scaler', StandardScaler()), ('xgb', xgb_model)])\n",
        "xgb_pipe.fit(X_train, y_train)\n",
        "y_proba_xgb = xgb_pipe.predict_proba(X_test)[:, 1]\n",
        "test_auc_xgb = roc_auc_score(y_test, y_proba_xgb)\n",
        "print(\"XGBoost Holdout AUC:\", round(test_auc_xgb, 3))\n",
        "\n",
        "base_learners = [\n",
        "    ('lr', LogisticRegression(C=0.1, random_state=23)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=23)),\n",
        "    ('xgb', xgb.XGBClassifier(random_state=23))\n",
        "]\n",
        "stacking_pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('stack', StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression(), cv=5))\n",
        "])\n",
        "stacking_pipe.fit(X_train, y_train)\n",
        "y_proba_stack = stacking_pipe.predict_proba(X_test)[:, 1]\n",
        "test_auc_stack = roc_auc_score(y_test, y_proba_stack)\n",
        "print(\"Stacking Holdout AUC:\", round(test_auc_stack, 3))\n",
        "\n",
        "print(f\"Class distribution: {y.mean():.3f}\")\n",
        "smote_pipe = ImbPipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(random_state=23)),\n",
        "    ('clf', LogisticRegression(penalty='l2', solver='liblinear', max_iter=3000))\n",
        "])\n",
        "smote_pipe.fit(X_train, y_train)\n",
        "y_proba_smote = smote_pipe.predict_proba(X_test)[:, 1]\n",
        "test_auc_smote = roc_auc_score(y_test, y_proba_smote)\n",
        "print(\"SMOTE Holdout AUC:\", round(test_auc_smote, 3))\n",
        "\n",
        "comparison_data = {\n",
        "    'Model': ['Original LR', 'XGBoost', 'Ensemble Stacking', 'SMOTE + LR'],\n",
        "    'AUC': [test_auc, test_auc_xgb, test_auc_stack, test_auc_smote],\n",
        "    'Improvement': ['Baseline', f\"+{test_auc_xgb-test_auc:.3f}\", f\"+{test_auc_stack-test_auc:.3f}\", f\"+{test_auc_smote-test_auc:.3f}\"]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {test_auc:.3f}\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC — Full Retirement (≥10 seasons)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "scaler = best_model.named_steps['scaler']\n",
        "clf = best_model.named_steps['clf']\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'coef': clf.coef_[0]\n",
        "}).sort_values(by='coef', key=lambda v: abs(v), ascending=False)\n",
        "print(coef_df.head(20))\n",
        "\n",
        "perm = permutation_importance(best_model, X_test, y_test, scoring='roc_auc', n_repeats=20, random_state=23)\n",
        "imp_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': perm.importances_mean\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "print(imp_df.head(15))\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=500, random_state=23, class_weight='balanced_subsample')\n",
        "gb = GradientBoostingClassifier(random_state=23)\n",
        "benchmarks = []\n",
        "for name, model in [('Random Forest', rf), ('GBM', gb)]:\n",
        "    scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "    benchmarks.append((name, scores.mean(), scores.std()))\n",
        "print(\"\\nCV AUC Benchmarks:\")\n",
        "for name, mean_auc, std_auc in benchmarks:\n",
        "    print(f\"{name}: {mean_auc:.3f} ± {std_auc:.3f}\")\n",
        "\n",
        "corr_vars = ['age', 'g', 'mp', 'ppg', 'rpg', 'apg', 'spg', 'bpg', 'tpg', 'fg_percent', 'x3p_percent']\n",
        "corr_names = ['Age', 'Games', 'Minutes', 'Points', 'Rebounds', 'Assists', 'Steals', 'Blocks', 'Turnovers', 'FG%', '3P%']\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr_matrix = X[corr_vars].corr()\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0, square=True, fmt='.2f', xticklabels=corr_names, yticklabels=corr_names)\n",
        "plt.title('Correlation Matrix of Performance Metrics')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "avg_probability = y_test.mean()\n",
        "features = ['age', 'g', 'fg_percent', 'mp', 'ppg', 'rpg', 'apg', 'spg', 'bpg', 'tpg']\n",
        "names = ['Age', 'Games', 'FG%', 'Minutes', 'Points', 'Rebounds', 'Assists', 'Steals', 'Blocks', 'Turnovers']\n",
        "for feature, name in zip(features, names):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    PartialDependenceDisplay.from_estimator(best_model, X_test, [feature], line_kw={'color': 'black', 'linewidth': 3})\n",
        "    plt.axhline(y=avg_probability, color='green', linestyle='--', linewidth=3, label=f'Avg: {avg_probability:.3f}')\n",
        "    plt.legend()\n",
        "    plt.title(f'PDP: {name}')\n",
        "    plt.ylabel('Fitted Probability')\n",
        "    plt.xlabel(name)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "sMmGK9SUV5DG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}